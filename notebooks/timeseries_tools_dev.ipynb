{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `timeseries_tools` Development Notebook\n",
    "This notebook is for developing a prototype Nowcast timeseries analysis package. The primary goal of this package is to be memory-efficient. As such, the results arrays are flattened to 2-D (time, space) so that land points can be removed. The 2-D dimensions are also ideal for some analyses like PCA. The basic workflow proceeds as follows:\n",
    "   * Flatten the model grid and mask to 2-D (time, space) and remove land indices\n",
    "   * Load, process, and flatten hourly Nowcast Results to 2-D (time, space) and remove land indices\n",
    "   * Concatenate consecutive 24 hour periods\n",
    "   * Reshape the concatenated `Numpy ndarray` to (time, depth, y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from salishsea_tools import nc_tools\n",
    "import progressbar\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "To be added to `timeseries_tools.py` in `salishsea_tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_GEM_mask(grid_GEM, grid_NEMO, mask_NEMO):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Preallocate\n",
    "    ngrid_GEM = grid_GEM['x'].shape[0] * grid_GEM['y'].shape[0]\n",
    "    mask_GEM = np.zeros(ngrid_GEM, dtype=int)\n",
    "\n",
    "    # Evaluate each point on GEM grid\n",
    "    with progressbar.ProgressBar(max_value=ngrid_GEM) as bar:\n",
    "        for index, coords in enumerate(zip(\n",
    "            grid_GEM['nav_lon'].values.reshape(ngrid_GEM) - 360,\n",
    "            grid_GEM['nav_lat'].values.reshape(ngrid_GEM))):\n",
    "\n",
    "            j, i = geo_tools.find_closest_model_point(coords[0], coords[1], grid_NEMO['nav_lon'], grid_NEMO['nav_lat'])\n",
    "            if j is np.nan or i is np.nan:\n",
    "                mask_GEM[index] = 0\n",
    "            else:\n",
    "                mask_GEM[index] = mask_NEMO[j, i].values\n",
    "                \n",
    "            # Update progress bar\n",
    "            bar.update(index)\n",
    "\n",
    "    # Reshape\n",
    "    mask_GEM = mask_GEM.reshape(grid_GEM['nav_lon'].shape)\n",
    "    \n",
    "    return mask_GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_coords(mask_in, dim_in, index=0, spacing=1):\n",
    "    \"\"\"Prepare the mask and grid for the selected timeseries slice, and reshape into 1 spatial dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    # Correct for depth dimension name\n",
    "    if dim_in.find('depth') is not -1:\n",
    "        dim = 'deptht'\n",
    "    else:\n",
    "        dim = dim_in\n",
    "    \n",
    "    # Create full gridded mask, grid and depth Numpy ndarrays\n",
    "    gridZ, gridY, gridX = np.meshgrid(mask_in.z, mask_in.y, mask_in.x, indexing='ij')\n",
    "    gridmask = xr.Dataset({\n",
    "        'tmask': (['deptht', 'y', 'x'], mask_in.tmask.isel(t=0).values.astype(bool)),\n",
    "        'depth': (['deptht', 'y', 'x'], mask_in.gdept_0.isel(t=0).values),\n",
    "        'gridZ': (['deptht', 'y', 'x'], gridZ),\n",
    "        'gridY': (['deptht', 'y', 'x'], gridY),\n",
    "        'gridX': (['deptht', 'y', 'x'], gridX),},\n",
    "        coords={'deptht': mask_in.gdept_1d.isel(t=0).values, 'y': mask_in.y, 'x': mask_in.x})\n",
    "    \n",
    "    # Slice and subsample mask\n",
    "    mask = gridmask.tmask.isel(**{dim: index}).values[::spacing, ::spacing]\n",
    "    \n",
    "    # Slice and subsample grid and depth into dict\n",
    "    coords = {\n",
    "        'depth': gridmask.depth.isel(**{dim: index}).values[::spacing, ::spacing],\n",
    "        'gridZ': gridmask.gridZ.isel(**{dim: index}).values[::spacing, ::spacing],\n",
    "        'gridY': gridmask.gridY.isel(**{dim: index}).values[::spacing, ::spacing],\n",
    "        'gridX': gridmask.gridX.isel(**{dim: index}).values[::spacing, ::spacing],\n",
    "    }\n",
    "    \n",
    "    # Number of grid points\n",
    "    ngrid = mask.shape[0] * mask.shape[1]\n",
    "    ngrid_water = mask.sum()\n",
    "    \n",
    "    # Reshape mask, grid, and depth\n",
    "    mask  =  mask.reshape(ngrid)\n",
    "    coords['depth'] = coords['depth'].reshape(ngrid)[mask]\n",
    "    coords['gridZ'] = coords['gridZ'].reshape(ngrid)[mask]\n",
    "    coords['gridY'] = coords['gridY'].reshape(ngrid)[mask]\n",
    "    coords['gridX'] = coords['gridX'].reshape(ngrid)[mask]\n",
    "    \n",
    "    return mask, coords, ngrid, ngrid_water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_to_ts(data_grid, mask, ngrid, ngrid_water, spacing=1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        \n",
    "    # Convert to Numpy ndarray, subsample, and reshape\n",
    "    data_flat = data_grid[:, ::spacing, ::spacing].reshape((-1, ngrid))\n",
    "    \n",
    "    # Preallocate trimmed array\n",
    "    data_trim = np.zeros((data_flat.shape[0], ngrid_water))\n",
    "    \n",
    "    # Trim land points\n",
    "    for tindex, data_t in enumerate(data_flat):\n",
    "        data_trim[tindex, :] = data_t[mask]\n",
    "    \n",
    "    return data_trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_to_grid(data_flat, coords, shape):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Preallocate gridded array\n",
    "    data_grid = np.zeros((data_flat.shape[0],) + shape)\n",
    "    \n",
    "    # Reshape flattened data to grid\n",
    "    for coord1, coord2, data_xyz in zip(*(coords + [data_flat.T])):\n",
    "        data_grid[:, coord1, coord2] = data_xyz\n",
    "    \n",
    "    return data_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_NEMO_timeseries(filenames, field, mask, dim, index=0, spacing=1, shape='grid', unstagger_dim=None):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reshape mask, grid, and depth\n",
    "    tmask, coords, ngrid, ngrid_water = reshape_coords(mask, dim, index=index, spacing=spacing)\n",
    "    \n",
    "    # Initialize output array\n",
    "    date = np.empty(0, dtype='datetime64[ns]')\n",
    "    data = np.empty((0, ngrid_water))\n",
    "    \n",
    "    # Loop through filenames\n",
    "    with progressbar.ProgressBar(max_value=len(filenames)) as bar:\n",
    "        for findex, filename in enumerate(filenames):\n",
    "\n",
    "            # Open NEMO results and flatten (depth averages would be added here)\n",
    "            data_grid = xr.open_dataset(filename)[field].isel(**{dim: index})\n",
    "\n",
    "            # Unstagger if velocity field\n",
    "            if unstagger_dim is not None:\n",
    "                data_grid = viz_tools.unstagger_xarray(data_grid, unstagger_dim)\n",
    "\n",
    "            # Reshape field\n",
    "            data_trim = reshape_to_ts(data_grid.values, tmask, ngrid, ngrid_water, spacing=spacing)\n",
    "\n",
    "            # Store trimmed arrays\n",
    "            date = np.concatenate([date, data_grid.time_counter.values])\n",
    "            data = np.concatenate([data, data_trim], axis=0)\n",
    "\n",
    "            # Update progress bar\n",
    "            bar.update(findex)\n",
    "    \n",
    "    # Reshape to grid\n",
    "    if shape is 'grid':\n",
    "    \n",
    "        # Correct for depth dimension name\n",
    "        if dim.find('depth') is not -1:\n",
    "            dim1, dim2, dimslice = 'gridY', 'gridX', 'z'\n",
    "        elif dim.find('y') is not -1:\n",
    "            dim1, dim2, dimslice = 'depth', 'gridX', 'y'\n",
    "        elif dim.find('x') is not -1:\n",
    "            dim1, dim2, dimslice = 'depth', 'gridY', 'x'\n",
    "\n",
    "        # Reshape data to grid\n",
    "        data = reshape_to_grid(data, [coords[dim1], coords[dim2]], mask.gdept_0.isel(**{'t': 0, dimslice: 0}).shape)\n",
    "\n",
    "        # Redefine coords for grid\n",
    "        coords = {'depth': mask.gdept_1d.values, 'gridZ': mask.z.values, 'gridY': mask.y.values, 'gridX': mask.x.values}\n",
    "    \n",
    "    # Coords dict\n",
    "    coords['date'] = date\n",
    "    \n",
    "    return data, coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (30 of 30) |###################################| Elapsed Time: 0:01:21 Time: 0:01:21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (898,720) into shape (720)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-82deb30461d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/ocean/bmoorema/research/MEOPAR/NEMO-forcing/grid/mesh_mask_downbyone2.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mT_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_NEMO_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'votemper'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deptht'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mT_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_to_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gridY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gridX'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdept_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a06d5751d7a9>\u001b[0m in \u001b[0;36mreshape_to_grid\u001b[0;34m(data_flat, coords, shape)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Reshape flattened data to grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcoord1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_xyz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdata_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_xyz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (898,720) into shape (720)"
     ]
    }
   ],
   "source": [
    "# Load Temperature\n",
    "timerange = ['2017 Jan 1 00:00', '2017 Jan 30 23:00']\n",
    "\n",
    "# Make a list of sequential filenames to loop through\n",
    "filenames = nc_tools.make_filename_list(timerange, 'T', model='nowcast-green', resolution='h')\n",
    "\n",
    "mask = xr.open_dataset('/ocean/bmoorema/research/MEOPAR/NEMO-forcing/grid/mesh_mask_downbyone2.nc')\n",
    "\n",
    "# Load, slice, flatten, etc (example is surface slice)\n",
    "T_flat, coords = load_NEMO_timeseries(filenames, 'votemper', mask, 'deptht')\n",
    "\n",
    "# Unflatten\n",
    "T_grid = reshape_to_grid(T_flat, [coords['gridY'], coords['gridX']], mask.gdept_0.isel(t=0, z=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
